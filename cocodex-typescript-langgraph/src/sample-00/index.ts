/**
 * Sample 00: Tool Loopì˜ í•µì‹¬ ê°œë…
 *
 * OpenAI Function Callingê³¼ Tool Loopì˜ ê¸°ë³¸ ë©”ì»¤ë‹ˆì¦˜ì„ ì´í•´í•©ë‹ˆë‹¤.
 *
 * í•µì‹¬ í¬ì¸íŠ¸:
 * 1. AIê°€ "í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•´ì•¼ í•œë‹¤"ê³  íŒë‹¨í•˜ëŠ” ë°©ì‹
 * 2. Tool ì‹¤í–‰ í›„ ê²°ê³¼ë¥¼ ë‹¤ì‹œ AIì—ê²Œ ì „ë‹¬í•˜ëŠ” íŒ¨í„´
 * 3. ë©€í‹°í„´: AI â†’ Tool â†’ AI â†’ (ë°˜ë³µ) â†’ ìµœì¢… ì‘ë‹µ
 *
 * ì‹¤í–‰: npm run sample-00
 */

import { promises as fs } from "node:fs";
import readline from "node:readline/promises";
import dotenv from "dotenv";
import OpenAI from "openai";

dotenv.config();

const openai = new OpenAI({
	apiKey: process.env.OPENAI_API_KEY,
});

// Tool ì •ì˜: AIì—ê²Œ "ì´ëŸ° í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤"ê³  ì•Œë ¤ì¤Œ
const tools: OpenAI.Chat.Completions.ChatCompletionTool[] = [
	{
		type: "function",
		function: {
			name: "read_file",
			description: "íŒŒì¼ì˜ ë‚´ìš©ì„ ì½ìŠµë‹ˆë‹¤",
			parameters: {
				type: "object",
				properties: {
					path: {
						type: "string",
						description: "ì½ì„ íŒŒì¼ì˜ ê²½ë¡œ",
					},
				},
				required: ["path"],
			},
		},
	},
	{
		type: "function",
		function: {
			name: "write_file",
			description: "íŒŒì¼ì— ë‚´ìš©ì„ ì”ë‹ˆë‹¤",
			parameters: {
				type: "object",
				properties: {
					path: { type: "string", description: "íŒŒì¼ ê²½ë¡œ" },
					content: { type: "string", description: "íŒŒì¼ ë‚´ìš©" },
				},
				required: ["path", "content"],
			},
		},
	},
];

// Tool ì‹¤í–‰ í•¨ìˆ˜
// biome-ignore lint/suspicious/noExplicitAny: Tool arguments are dynamic from OpenAI API
async function executeTool(toolName: string, args: any): Promise<string> {
	console.log(`    ğŸ”§ [Tool ì‹¤í–‰] ${toolName}(${JSON.stringify(args)})`);

	try {
		switch (toolName) {
			case "read_file": {
				const content = await fs.readFile(args.path, "utf-8");
				console.log(
					`    ğŸ“„ [Tool ê²°ê³¼] íŒŒì¼ ì½ê¸° ì„±ê³µ (${content.length} ê¸€ì)`,
				);
				return content;
			}

			case "write_file":
				await fs.writeFile(args.path, args.content, "utf-8");
				console.log(`    âœ… [Tool ê²°ê³¼] íŒŒì¼ ì“°ê¸° ì™„ë£Œ`);
				return `íŒŒì¼ ${args.path}ì— ì‘ì„± ì™„ë£Œ`;

			default:
				throw new Error(`Unknown tool: ${toolName}`);
		}
	} catch (error) {
		const errorMsg = `ì˜¤ë¥˜: ${error}`;
		console.log(`    âŒ [Tool ì˜¤ë¥˜] ${errorMsg}`);
		return errorMsg;
	}
}

async function main() {
	console.log("ğŸ¯ Sample 00: Tool Loopì˜ í•µì‹¬ ê°œë…\n");
	console.log("=".repeat(60));

	// ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
	const rl = readline.createInterface({
		input: process.stdin,
		output: process.stdout,
	});

	const userInput = await rl.question(
		"\nğŸ’¬ ì‹¤í–‰í•  ì‘ì—…ì„ ì…ë ¥í•˜ì„¸ìš” (Enter = ê¸°ë³¸ ë°ëª¨): ",
	);
	rl.close();

	// ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
	const defaultPrompt =
		"sample-00-test.txt íŒŒì¼ì— 'Hello from Cocodex Sample 00!'ë¥¼ ì“°ê³ , ê·¸ íŒŒì¼ì„ ë‹¤ì‹œ ì½ì–´ì„œ ë‚´ìš©ì„ ì•Œë ¤ì¤˜.";
	const userPrompt = userInput.trim() || defaultPrompt;

	console.log(`\nğŸ“ ì‹¤í–‰ ì‘ì—…: ${userPrompt}\n`);
	console.log("=".repeat(60));

	const messages: OpenAI.Chat.Completions.ChatCompletionMessageParam[] = [
		{
			role: "system",
			content: "ë‹¹ì‹ ì€ íŒŒì¼ ì‘ì—…ì„ ë„ì™€ì£¼ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.",
		},
		{
			role: "user",
			content: userPrompt,
		},
	];

	let iteration = 0;
	const MAX_ITERATIONS = 10;

	// Tool Loop: AIê°€ ë” ì´ìƒ toolì„ í˜¸ì¶œí•˜ì§€ ì•Šì„ ë•Œê¹Œì§€ ë°˜ë³µ
	while (iteration < MAX_ITERATIONS) {
		iteration++;
		console.log(`\nğŸ“ [ë°˜ë³µ ${iteration}] AI í˜¸ì¶œ ì¤‘...`);

		const response = await openai.chat.completions.create({
			model: process.env.OPENAI_MODEL || "gpt-5o",
			messages: messages,
			tools: tools,
			tool_choice: "auto", // AIê°€ í•„ìš”í•˜ë©´ tool ì‚¬ìš©, ì•„ë‹ˆë©´ ì¼ë°˜ ì‘ë‹µ
			temperature: parseFloat(process.env.OPENAI_TEMPERATURE || "0.2"),
		});

		const responseMessage = response.choices[0].message;
		messages.push(responseMessage);

		// Case 1: AIê°€ toolì„ í˜¸ì¶œí•˜ë ¤ê³  í•¨
		if (responseMessage.tool_calls && responseMessage.tool_calls.length > 0) {
			console.log(
				`  ğŸ’­ [AI íŒë‹¨] ${responseMessage.tool_calls.length}ê°œì˜ Tool í˜¸ì¶œ í•„ìš”`,
			);

			// ê° tool call ì‹¤í–‰
			for (const toolCall of responseMessage.tool_calls) {
				const toolName = toolCall.function.name;
				const toolArgs = JSON.parse(toolCall.function.arguments);

				// ì‹¤ì œ í•¨ìˆ˜ ì‹¤í–‰
				const result = await executeTool(toolName, toolArgs);

				// ê²°ê³¼ë¥¼ AIì—ê²Œ ë‹¤ì‹œ ì „ë‹¬ (ì¤‘ìš”!)
				messages.push({
					role: "tool",
					tool_call_id: toolCall.id,
					content: result,
				});
			}

			// ë‹¤ìŒ ë°˜ë³µìœ¼ë¡œ ê³„ì† (AIê°€ tool ê²°ê³¼ë¥¼ ë³´ê³  ë‹¤ì‹œ íŒë‹¨)
			continue;
		}

		// Case 2: AIê°€ ìµœì¢… ì‘ë‹µì„ ìƒì„±í•¨
		console.log(`  âœ… [AI íŒë‹¨] ìµœì¢… ì‘ë‹µ ìƒì„±\n`);
		console.log("=".repeat(60));
		console.log("ğŸ¤– ìµœì¢… AI ì‘ë‹µ:");
		console.log(responseMessage.content);
		console.log("=".repeat(60));
		break;
	}

	if (iteration >= MAX_ITERATIONS) {
		console.log("\nâš ï¸  ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬ (ë¬´í•œ ë£¨í”„ ë°©ì§€)");
	}

	console.log(`\nğŸ“Š í†µê³„: ${iteration}ë²ˆ ë°˜ë³µ, ì´ ${messages.length}ê°œ ë©”ì‹œì§€`);

	console.log("\nğŸ’¡ í•µì‹¬ ê°œë… ì •ë¦¬:");
	console.log("  1. Tool Schema: JSON Schemaë¡œ í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ë¥¼ AIì—ê²Œ ì„¤ëª…");
	console.log(
		"  2. tool_calls: AIì˜ ì‘ë‹µì— 'ì´ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ë¼'ëŠ” ì§€ì‹œê°€ í¬í•¨ë¨",
	);
	console.log("  3. role: 'tool': Tool ì‹¤í–‰ ê²°ê³¼ë¥¼ AIì—ê²Œ í”¼ë“œë°±");
	console.log("  4. Loop: AI â†’ Tool â†’ AI â†’ ... â†’ ìµœì¢… ì‘ë‹µ");
	console.log("  5. ììœ¨ì„±: AIê°€ ìŠ¤ìŠ¤ë¡œ tool ì‚¬ìš© ì—¬ë¶€ì™€ ìˆœì„œë¥¼ ê²°ì •\n");

	console.log("ğŸš€ ë‹¤ìŒ ë‹¨ê³„: npm run sample-01 (LangGraphë¡œ ì´ íŒ¨í„´ì„ êµ¬ì¡°í™”)");
}

main().catch(console.error);
